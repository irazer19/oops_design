
Purpose:
1. Prevent Abuse: Rate limiters are used to prevent users from making too many requests in a given time frame,
which can be a form of abuse or an attack on the system.
2. Cost Reduction: By controlling the number of requests, companies can reduce the number of servers needed to manage
traffic, thus lowering costs.
3. System Performance: Implementing rate limiting can optimize system performance by ensuring that resources are not
overwhelmed by excessive requests


Algorithms:
1. Token bucket: Every defined interval (say minutes), x number of tokens are filled in the bucket and each request
consumes a token.

2. Leaky bucket: Incoming data packets are temporarily stored in a "bucket" (a buffer), and then released at a steady,
constant rate, much like water leaking from a hole in a bucket.
If the incoming data rate exceeds the leak rate (the rate at which data is being sent out), the excess data fills up
the bucket. If the data continues to come in at a rate that exceeds the leak rate and the bucket becomes full, the
excess data "overflows" and is discarded, similar to water spilling over the sides of a full bucket. its not efficient
in case of burst of data incoming because of overflow of the bucket.

3. Fixed window counter: This algorithm allows a fixed number of requests per time window (e.g., per second, minute, hour)
its disadvantage is that at the edge of the window you may have double the allowed requests.

4. Sliding window counter: We count the number of requests in the last x interval(say minutes).
The Sliding Window Counter algorithm continuously tracks requests and maintains a "sliding window" that moves forward
in time, ensuring that request counts are always up-to-date


Componenets needed:
1. Redis to store the counter info.
2. Cache to store the config files for rules and algorithm settings, etc
The config files will be stored in the disk but we can load it in the cache for the rate-limiter.




